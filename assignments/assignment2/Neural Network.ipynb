{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for FullyConnectedLayer_0_W\n",
      "Gradient check passed!\n",
      "Checking gradient for FullyConnectedLayer_0_B\n",
      "Gradient check passed!\n",
      "Checking gradient for FullyConnectedLayer_2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for FullyConnectedLayer_2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for FullyConnectedLayer_0_W\n",
      "Gradient check passed!\n",
      "Checking gradient for FullyConnectedLayer_0_B\n",
      "Gradient check passed!\n",
      "Checking gradient for FullyConnectedLayer_2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for FullyConnectedLayer_2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.15"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "samples = 900\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:samples]), train_y[:samples])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "135"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_y[:samples]==2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302029, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301685, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301851, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302623, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301124, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302831, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301638, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302170, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302455, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302807, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302832, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303278, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301772, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302333, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302433, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301941, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302173, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7fa56aadf880>]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.275985, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.347515, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264348, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253264, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265011, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212698, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302624, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311032, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234316, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.353994, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217454, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.378711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256101, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264767, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274562, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.322051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308033, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317549, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262630, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308261, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264990, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278636, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267083, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276510, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314133, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256404, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295822, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278750, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280567, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240982, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315651, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.351801, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319693, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.295926, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.345443, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.310013, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.326544, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.255641, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.199259, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.164561, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.025661, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.883798, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.263931, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.662918, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.245522, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.943906, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.663953, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.042200, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.418303, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.519709, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.823944, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.022291, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.585656, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.937038, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.908215, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.233499, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.095108, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.718242, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.162756, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.015933, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.363952, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.842670, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.657567, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.388463, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.911120, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.693765, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.010436, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.115900, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.613706, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.738574, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.885192, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 2.474042, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.119274, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.672047, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.767860, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.478802, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.926619, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.337383, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.683186, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.660081, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.401881, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.635264, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.635617, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.622938, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.854111, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.556636, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634732, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.076198, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.007559, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.531114, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.041336, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.022564, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.647379, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.369538, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.379903, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.986917, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.318972, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.283966, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.936269, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.196061, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.739352, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634901, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.201189, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.582981, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.742143, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.293135, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.748190, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.976545, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.357876, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.992895, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602046, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602167, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.173057, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.312798, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.564551, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.961713, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.274091, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.304703, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.958926, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.377168, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.657193, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.389767, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.576803, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.556738, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.175409, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.322616, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.251510, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.060407, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.661861, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.227308, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.597969, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.887250, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.338688, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.842966, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.160604, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.347215, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.223119, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.436648, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.535320, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.249121, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.248964, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.549803, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.259687, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.097239, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.324286, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.315431, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.420746, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.443017, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.301618, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.533658, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.607993, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.239065, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.649177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.174445, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.602848, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.363682, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.160640, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.197888, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.126413, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.008120, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.643235, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.592807, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.412599, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.212850, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.196541, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.280346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.403204, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.229377, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.400568, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.391042, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.102808, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.445285, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.406323, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.219193, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.449330, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.304464, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.494726, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.327706, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.361608, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.460816, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.424061, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.315602, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.260196, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.253574, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.079124, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 1.764302, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.176783, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.599997, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.054212, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.029767, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.632275, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 0.632832, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.091659, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.121665, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.800057, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.768538, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.495810, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.470446, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.343351, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.394819, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.282542, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 400, reg = 1e-2)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=3e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.246778, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243479, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.140358, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.990722, Train accuracy: 0.264889, val accuracy: 0.269000\n",
      "Loss: 1.980078, Train accuracy: 0.299222, val accuracy: 0.305000\n",
      "Loss: 1.794562, Train accuracy: 0.386000, val accuracy: 0.381000\n",
      "Loss: 1.633662, Train accuracy: 0.466667, val accuracy: 0.461000\n",
      "Loss: 1.471626, Train accuracy: 0.529111, val accuracy: 0.533000\n",
      "Loss: 1.142530, Train accuracy: 0.579333, val accuracy: 0.566000\n",
      "Loss: 1.513196, Train accuracy: 0.608667, val accuracy: 0.591000\n",
      "Loss: 1.201923, Train accuracy: 0.636778, val accuracy: 0.618000\n",
      "Loss: 1.256758, Train accuracy: 0.667778, val accuracy: 0.651000\n",
      "Loss: 1.228439, Train accuracy: 0.684000, val accuracy: 0.665000\n",
      "Loss: 1.254179, Train accuracy: 0.697889, val accuracy: 0.679000\n",
      "Loss: 1.185938, Train accuracy: 0.707889, val accuracy: 0.684000\n",
      "Loss: 1.263526, Train accuracy: 0.718556, val accuracy: 0.685000\n",
      "Loss: 1.423800, Train accuracy: 0.712667, val accuracy: 0.690000\n",
      "Loss: 0.852622, Train accuracy: 0.732111, val accuracy: 0.710000\n",
      "Loss: 1.127731, Train accuracy: 0.737778, val accuracy: 0.707000\n",
      "Loss: 0.873136, Train accuracy: 0.751222, val accuracy: 0.714000\n",
      "Loss: 0.873123, Train accuracy: 0.748333, val accuracy: 0.705000\n",
      "Loss: 1.225267, Train accuracy: 0.761889, val accuracy: 0.710000\n",
      "Loss: 1.101060, Train accuracy: 0.758667, val accuracy: 0.693000\n",
      "Loss: 1.389337, Train accuracy: 0.768556, val accuracy: 0.716000\n",
      "Loss: 0.929693, Train accuracy: 0.777111, val accuracy: 0.722000\n",
      "Loss: 0.923922, Train accuracy: 0.781556, val accuracy: 0.722000\n",
      "Loss: 0.867592, Train accuracy: 0.793000, val accuracy: 0.717000\n",
      "Loss: 0.999904, Train accuracy: 0.782778, val accuracy: 0.735000\n",
      "Loss: 0.851194, Train accuracy: 0.800000, val accuracy: 0.728000\n",
      "Loss: 0.505426, Train accuracy: 0.800333, val accuracy: 0.723000\n",
      "Loss: 0.728811, Train accuracy: 0.806556, val accuracy: 0.726000\n",
      "Loss: 0.761330, Train accuracy: 0.814111, val accuracy: 0.734000\n",
      "Loss: 0.870261, Train accuracy: 0.819111, val accuracy: 0.740000\n",
      "Loss: 1.045845, Train accuracy: 0.820444, val accuracy: 0.735000\n",
      "Loss: 0.763823, Train accuracy: 0.817222, val accuracy: 0.740000\n",
      "Loss: 1.084919, Train accuracy: 0.831111, val accuracy: 0.736000\n",
      "Loss: 0.670800, Train accuracy: 0.831333, val accuracy: 0.746000\n",
      "Loss: 0.916688, Train accuracy: 0.821000, val accuracy: 0.751000\n",
      "Loss: 0.759977, Train accuracy: 0.834111, val accuracy: 0.748000\n",
      "Loss: 0.942579, Train accuracy: 0.840444, val accuracy: 0.747000\n",
      "new leader with val_acc=0.747 and params: [hidden_layer_size=100 reg_strength=0.001 learning_rate=0.01]\n",
      "Loss: 2.340605, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.211407, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.203604, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.966267, Train accuracy: 0.256222, val accuracy: 0.254000\n",
      "Loss: 2.103810, Train accuracy: 0.297778, val accuracy: 0.301000\n",
      "Loss: 1.725561, Train accuracy: 0.380222, val accuracy: 0.384000\n",
      "Loss: 1.589085, Train accuracy: 0.457111, val accuracy: 0.447000\n",
      "Loss: 1.572653, Train accuracy: 0.525556, val accuracy: 0.527000\n",
      "Loss: 1.008622, Train accuracy: 0.570889, val accuracy: 0.560000\n",
      "Loss: 1.414890, Train accuracy: 0.616111, val accuracy: 0.606000\n",
      "Loss: 1.107791, Train accuracy: 0.638556, val accuracy: 0.635000\n",
      "Loss: 1.118353, Train accuracy: 0.671556, val accuracy: 0.657000\n",
      "Loss: 1.236013, Train accuracy: 0.674222, val accuracy: 0.660000\n",
      "Loss: 1.243948, Train accuracy: 0.684000, val accuracy: 0.681000\n",
      "Loss: 1.104979, Train accuracy: 0.713889, val accuracy: 0.698000\n",
      "Loss: 1.340482, Train accuracy: 0.727778, val accuracy: 0.690000\n",
      "Loss: 0.836468, Train accuracy: 0.722889, val accuracy: 0.702000\n",
      "Loss: 0.696731, Train accuracy: 0.730333, val accuracy: 0.699000\n",
      "Loss: 1.524251, Train accuracy: 0.758222, val accuracy: 0.710000\n",
      "Loss: 0.550217, Train accuracy: 0.762111, val accuracy: 0.708000\n",
      "Loss: 0.805935, Train accuracy: 0.772111, val accuracy: 0.716000\n",
      "Loss: 0.637578, Train accuracy: 0.781556, val accuracy: 0.724000\n",
      "Loss: 0.571078, Train accuracy: 0.781556, val accuracy: 0.725000\n",
      "Loss: 0.882814, Train accuracy: 0.795444, val accuracy: 0.730000\n",
      "Loss: 0.518302, Train accuracy: 0.794556, val accuracy: 0.731000\n",
      "Loss: 0.748639, Train accuracy: 0.792889, val accuracy: 0.737000\n",
      "Loss: 1.077863, Train accuracy: 0.804111, val accuracy: 0.745000\n",
      "Loss: 0.890301, Train accuracy: 0.812889, val accuracy: 0.741000\n",
      "Loss: 0.759167, Train accuracy: 0.826778, val accuracy: 0.743000\n",
      "Loss: 0.655914, Train accuracy: 0.826111, val accuracy: 0.746000\n",
      "Loss: 0.621542, Train accuracy: 0.823778, val accuracy: 0.724000\n",
      "Loss: 0.490983, Train accuracy: 0.832222, val accuracy: 0.733000\n",
      "Loss: 0.653683, Train accuracy: 0.842333, val accuracy: 0.740000\n",
      "Loss: 0.627095, Train accuracy: 0.847000, val accuracy: 0.734000\n",
      "Loss: 0.506244, Train accuracy: 0.854222, val accuracy: 0.741000\n",
      "Loss: 0.710488, Train accuracy: 0.851778, val accuracy: 0.751000\n",
      "Loss: 0.574828, Train accuracy: 0.851111, val accuracy: 0.733000\n",
      "Loss: 0.699731, Train accuracy: 0.854111, val accuracy: 0.743000\n",
      "Loss: 0.535974, Train accuracy: 0.866556, val accuracy: 0.744000\n",
      "Loss: 0.549576, Train accuracy: 0.861667, val accuracy: 0.742000\n",
      "Loss: 2.158121, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244210, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.133886, Train accuracy: 0.263778, val accuracy: 0.260000\n",
      "Loss: 1.830322, Train accuracy: 0.320889, val accuracy: 0.315000\n",
      "Loss: 1.805234, Train accuracy: 0.410111, val accuracy: 0.395000\n",
      "Loss: 1.588882, Train accuracy: 0.483222, val accuracy: 0.476000\n",
      "Loss: 1.333050, Train accuracy: 0.533889, val accuracy: 0.536000\n",
      "Loss: 1.593893, Train accuracy: 0.582444, val accuracy: 0.575000\n",
      "Loss: 1.569312, Train accuracy: 0.611111, val accuracy: 0.593000\n",
      "Loss: 0.971974, Train accuracy: 0.636667, val accuracy: 0.610000\n",
      "Loss: 1.117639, Train accuracy: 0.667556, val accuracy: 0.648000\n",
      "Loss: 1.352626, Train accuracy: 0.682444, val accuracy: 0.659000\n",
      "Loss: 1.057029, Train accuracy: 0.685889, val accuracy: 0.671000\n",
      "Loss: 0.974136, Train accuracy: 0.714889, val accuracy: 0.691000\n",
      "Loss: 1.058151, Train accuracy: 0.732667, val accuracy: 0.710000\n",
      "Loss: 1.074392, Train accuracy: 0.722778, val accuracy: 0.682000\n",
      "Loss: 0.916748, Train accuracy: 0.733778, val accuracy: 0.697000\n",
      "Loss: 1.189564, Train accuracy: 0.753556, val accuracy: 0.713000\n",
      "Loss: 0.999597, Train accuracy: 0.759444, val accuracy: 0.717000\n",
      "Loss: 0.892021, Train accuracy: 0.765000, val accuracy: 0.708000\n",
      "Loss: 0.797816, Train accuracy: 0.769667, val accuracy: 0.714000\n",
      "Loss: 0.966708, Train accuracy: 0.766667, val accuracy: 0.715000\n",
      "Loss: 0.775729, Train accuracy: 0.779444, val accuracy: 0.727000\n",
      "Loss: 0.871936, Train accuracy: 0.785222, val accuracy: 0.727000\n",
      "Loss: 0.966319, Train accuracy: 0.784111, val accuracy: 0.731000\n",
      "Loss: 0.908254, Train accuracy: 0.801778, val accuracy: 0.737000\n",
      "Loss: 0.890923, Train accuracy: 0.797778, val accuracy: 0.730000\n",
      "Loss: 0.748042, Train accuracy: 0.807222, val accuracy: 0.724000\n",
      "Loss: 1.172049, Train accuracy: 0.799556, val accuracy: 0.743000\n",
      "Loss: 1.041353, Train accuracy: 0.811667, val accuracy: 0.735000\n",
      "Loss: 1.289243, Train accuracy: 0.815222, val accuracy: 0.735000\n",
      "Loss: 0.980760, Train accuracy: 0.832000, val accuracy: 0.753000\n",
      "Loss: 0.840364, Train accuracy: 0.825333, val accuracy: 0.737000\n",
      "Loss: 0.969540, Train accuracy: 0.833000, val accuracy: 0.758000\n",
      "Loss: 0.844962, Train accuracy: 0.835556, val accuracy: 0.738000\n",
      "Loss: 0.687312, Train accuracy: 0.842111, val accuracy: 0.743000\n",
      "Loss: 1.211057, Train accuracy: 0.843000, val accuracy: 0.757000\n",
      "Loss: 0.758336, Train accuracy: 0.839000, val accuracy: 0.737000\n",
      "Loss: 0.679276, Train accuracy: 0.854111, val accuracy: 0.753000\n",
      "new leader with val_acc=0.753 and params: [hidden_layer_size=120 reg_strength=0.001 learning_rate=0.01]\n",
      "Loss: 2.209260, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.138162, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.151553, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.972861, Train accuracy: 0.271000, val accuracy: 0.270000\n",
      "Loss: 2.104054, Train accuracy: 0.318667, val accuracy: 0.328000\n",
      "Loss: 1.659351, Train accuracy: 0.412778, val accuracy: 0.407000\n",
      "Loss: 1.472873, Train accuracy: 0.478556, val accuracy: 0.463000\n",
      "Loss: 1.265774, Train accuracy: 0.548333, val accuracy: 0.539000\n",
      "Loss: 1.335953, Train accuracy: 0.595000, val accuracy: 0.575000\n",
      "Loss: 1.120856, Train accuracy: 0.633667, val accuracy: 0.618000\n",
      "Loss: 1.075772, Train accuracy: 0.660444, val accuracy: 0.639000\n",
      "Loss: 1.071050, Train accuracy: 0.673222, val accuracy: 0.647000\n",
      "Loss: 1.377710, Train accuracy: 0.694556, val accuracy: 0.679000\n",
      "Loss: 1.106871, Train accuracy: 0.708889, val accuracy: 0.677000\n",
      "Loss: 0.967363, Train accuracy: 0.726889, val accuracy: 0.691000\n",
      "Loss: 0.751004, Train accuracy: 0.724111, val accuracy: 0.680000\n",
      "Loss: 0.864342, Train accuracy: 0.743000, val accuracy: 0.710000\n",
      "Loss: 1.062583, Train accuracy: 0.738222, val accuracy: 0.713000\n",
      "Loss: 0.796252, Train accuracy: 0.764333, val accuracy: 0.711000\n",
      "Loss: 0.770807, Train accuracy: 0.761333, val accuracy: 0.708000\n",
      "Loss: 1.077324, Train accuracy: 0.760222, val accuracy: 0.701000\n",
      "Loss: 0.665414, Train accuracy: 0.768222, val accuracy: 0.718000\n",
      "Loss: 0.906260, Train accuracy: 0.787556, val accuracy: 0.712000\n",
      "Loss: 0.601267, Train accuracy: 0.776333, val accuracy: 0.706000\n",
      "Loss: 0.620227, Train accuracy: 0.803889, val accuracy: 0.723000\n",
      "Loss: 0.861522, Train accuracy: 0.799222, val accuracy: 0.731000\n",
      "Loss: 0.627026, Train accuracy: 0.810667, val accuracy: 0.729000\n",
      "Loss: 0.872769, Train accuracy: 0.810444, val accuracy: 0.725000\n",
      "Loss: 0.555664, Train accuracy: 0.822111, val accuracy: 0.727000\n",
      "Loss: 0.652440, Train accuracy: 0.830444, val accuracy: 0.736000\n",
      "Loss: 0.776877, Train accuracy: 0.833111, val accuracy: 0.729000\n",
      "Loss: 0.616526, Train accuracy: 0.829889, val accuracy: 0.734000\n",
      "Loss: 0.692902, Train accuracy: 0.824111, val accuracy: 0.732000\n",
      "Loss: 0.462029, Train accuracy: 0.842667, val accuracy: 0.724000\n",
      "Loss: 0.696591, Train accuracy: 0.849889, val accuracy: 0.738000\n",
      "Loss: 0.378330, Train accuracy: 0.858778, val accuracy: 0.748000\n",
      "Loss: 0.646257, Train accuracy: 0.854778, val accuracy: 0.735000\n",
      "Loss: 0.563826, Train accuracy: 0.863556, val accuracy: 0.753000\n",
      "Loss: 0.633596, Train accuracy: 0.866000, val accuracy: 0.751000\n",
      "Loss: 0.461757, Train accuracy: 0.868778, val accuracy: 0.748000\n",
      "Loss: 2.122585, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202413, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.117935, Train accuracy: 0.196778, val accuracy: 0.206000\n",
      "Loss: 2.058107, Train accuracy: 0.273111, val accuracy: 0.268000\n",
      "Loss: 1.777889, Train accuracy: 0.314444, val accuracy: 0.327000\n",
      "Loss: 1.552108, Train accuracy: 0.424444, val accuracy: 0.416000\n",
      "Loss: 1.624703, Train accuracy: 0.479778, val accuracy: 0.469000\n",
      "Loss: 1.513320, Train accuracy: 0.539333, val accuracy: 0.550000\n",
      "Loss: 1.147800, Train accuracy: 0.594111, val accuracy: 0.586000\n",
      "Loss: 1.210620, Train accuracy: 0.612556, val accuracy: 0.600000\n",
      "Loss: 1.289792, Train accuracy: 0.643444, val accuracy: 0.620000\n",
      "Loss: 1.183854, Train accuracy: 0.666222, val accuracy: 0.637000\n",
      "Loss: 1.379631, Train accuracy: 0.677444, val accuracy: 0.667000\n",
      "Loss: 1.223764, Train accuracy: 0.688889, val accuracy: 0.669000\n",
      "Loss: 0.817801, Train accuracy: 0.699889, val accuracy: 0.680000\n",
      "Loss: 1.168915, Train accuracy: 0.726444, val accuracy: 0.689000\n",
      "Loss: 0.959982, Train accuracy: 0.719111, val accuracy: 0.685000\n",
      "Loss: 1.159481, Train accuracy: 0.732778, val accuracy: 0.706000\n",
      "Loss: 0.949910, Train accuracy: 0.747444, val accuracy: 0.702000\n",
      "Loss: 1.249396, Train accuracy: 0.746444, val accuracy: 0.713000\n",
      "Loss: 0.937782, Train accuracy: 0.761778, val accuracy: 0.728000\n",
      "Loss: 0.965099, Train accuracy: 0.754111, val accuracy: 0.696000\n",
      "Loss: 0.698469, Train accuracy: 0.779556, val accuracy: 0.736000\n",
      "Loss: 1.356508, Train accuracy: 0.784667, val accuracy: 0.736000\n",
      "Loss: 0.693269, Train accuracy: 0.790111, val accuracy: 0.735000\n",
      "Loss: 0.886213, Train accuracy: 0.797333, val accuracy: 0.741000\n",
      "Loss: 1.002150, Train accuracy: 0.806889, val accuracy: 0.751000\n",
      "Loss: 0.794875, Train accuracy: 0.804444, val accuracy: 0.732000\n",
      "Loss: 0.718953, Train accuracy: 0.811444, val accuracy: 0.748000\n",
      "Loss: 0.735895, Train accuracy: 0.807889, val accuracy: 0.752000\n",
      "Loss: 1.058655, Train accuracy: 0.816444, val accuracy: 0.750000\n",
      "Loss: 0.847808, Train accuracy: 0.825222, val accuracy: 0.751000\n",
      "Loss: 0.940031, Train accuracy: 0.817222, val accuracy: 0.730000\n",
      "Loss: 0.826160, Train accuracy: 0.824222, val accuracy: 0.747000\n",
      "Loss: 0.718212, Train accuracy: 0.838111, val accuracy: 0.750000\n",
      "Loss: 0.994058, Train accuracy: 0.821444, val accuracy: 0.738000\n",
      "Loss: 0.943805, Train accuracy: 0.842111, val accuracy: 0.747000\n",
      "Loss: 0.636952, Train accuracy: 0.851444, val accuracy: 0.743000\n",
      "Loss: 0.717971, Train accuracy: 0.852000, val accuracy: 0.757000\n",
      "Loss: 0.617787, Train accuracy: 0.849556, val accuracy: 0.759000\n",
      "new leader with val_acc=0.759 and params: [hidden_layer_size=150 reg_strength=0.001 learning_rate=0.01]\n",
      "Loss: 2.220716, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.180617, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.143588, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.198646, Train accuracy: 0.258889, val accuracy: 0.255000\n",
      "Loss: 1.921163, Train accuracy: 0.339222, val accuracy: 0.346000\n",
      "Loss: 1.755320, Train accuracy: 0.400111, val accuracy: 0.405000\n",
      "Loss: 1.629114, Train accuracy: 0.496778, val accuracy: 0.502000\n",
      "Loss: 1.564213, Train accuracy: 0.551333, val accuracy: 0.546000\n",
      "Loss: 1.240865, Train accuracy: 0.611889, val accuracy: 0.605000\n",
      "Loss: 1.069523, Train accuracy: 0.633889, val accuracy: 0.631000\n",
      "Loss: 1.112275, Train accuracy: 0.649556, val accuracy: 0.628000\n",
      "Loss: 1.066768, Train accuracy: 0.669000, val accuracy: 0.660000\n",
      "Loss: 1.086398, Train accuracy: 0.692556, val accuracy: 0.661000\n",
      "Loss: 0.969773, Train accuracy: 0.690111, val accuracy: 0.682000\n",
      "Loss: 0.898867, Train accuracy: 0.720889, val accuracy: 0.686000\n",
      "Loss: 0.757937, Train accuracy: 0.722556, val accuracy: 0.701000\n",
      "Loss: 0.874116, Train accuracy: 0.745556, val accuracy: 0.717000\n",
      "Loss: 0.766862, Train accuracy: 0.749111, val accuracy: 0.719000\n",
      "Loss: 0.622279, Train accuracy: 0.759444, val accuracy: 0.718000\n",
      "Loss: 0.872116, Train accuracy: 0.779778, val accuracy: 0.728000\n",
      "Loss: 0.784802, Train accuracy: 0.761222, val accuracy: 0.707000\n",
      "Loss: 0.765858, Train accuracy: 0.791333, val accuracy: 0.731000\n",
      "Loss: 0.658579, Train accuracy: 0.795889, val accuracy: 0.738000\n",
      "Loss: 0.735763, Train accuracy: 0.787000, val accuracy: 0.710000\n",
      "Loss: 0.743457, Train accuracy: 0.803444, val accuracy: 0.735000\n",
      "Loss: 0.644998, Train accuracy: 0.826333, val accuracy: 0.750000\n",
      "Loss: 0.998467, Train accuracy: 0.828333, val accuracy: 0.754000\n",
      "Loss: 0.504805, Train accuracy: 0.830889, val accuracy: 0.749000\n",
      "Loss: 0.745919, Train accuracy: 0.841667, val accuracy: 0.745000\n",
      "Loss: 0.582790, Train accuracy: 0.830333, val accuracy: 0.727000\n",
      "Loss: 0.417585, Train accuracy: 0.836778, val accuracy: 0.736000\n",
      "Loss: 0.809385, Train accuracy: 0.850444, val accuracy: 0.749000\n",
      "Loss: 0.576511, Train accuracy: 0.854444, val accuracy: 0.744000\n",
      "Loss: 0.545871, Train accuracy: 0.861889, val accuracy: 0.751000\n",
      "Loss: 0.445764, Train accuracy: 0.869889, val accuracy: 0.747000\n",
      "Loss: 0.476836, Train accuracy: 0.867444, val accuracy: 0.741000\n",
      "Loss: 0.687155, Train accuracy: 0.861667, val accuracy: 0.742000\n",
      "Loss: 0.309787, Train accuracy: 0.883222, val accuracy: 0.748000\n",
      "Loss: 0.479766, Train accuracy: 0.872778, val accuracy: 0.742000\n",
      "Loss: 0.922706, Train accuracy: 0.883333, val accuracy: 0.743000\n",
      "best validation accuracy achieved: 0.759000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [1e-2]\n",
    "reg_strengths = [1e-3, 1e-4]\n",
    "learning_rate_decay = 0.995\n",
    "hidden_layer_sizes = [100, 120, 150]\n",
    "num_epochs = 40\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "for hidden_layer_size in hidden_layer_sizes:\n",
    "    for reg_strength in reg_strengths:\n",
    "        for learning_rate in learning_rates:\n",
    "            model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hidden_layer_size, reg = reg_strength)\n",
    "            dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "            trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=learning_rate, num_epochs=num_epochs, batch_size=batch_size, learning_rate_decay=learning_rate_decay)\n",
    "\n",
    "            loss_history, train_history, val_history = trainer.fit()\n",
    "            if best_val_accuracy < val_history[-1]:\n",
    "                print(f\"new leader with val_acc={val_history[-1]} and params: [{hidden_layer_size=} {reg_strength=} {learning_rate=}]\")\n",
    "                best_val_accuracy = val_history[-1]\n",
    "                best_classifier = model\n",
    "\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7fa552b813a0>]"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x504 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.731000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "new leader with val_acc=0.759 and params: [hidden_layer_size=150 reg_strength=0.001 learning_rate=0.01]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "my-virtualenv-name",
   "language": "python",
   "display_name": "my-virtualenv-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}